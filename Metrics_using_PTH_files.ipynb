{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4b90ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as PILImage\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl.drawing.image import Image as XLImage\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, roc_curve, precision_recall_curve,\n",
    "    auc, average_precision_score\n",
    ")\n",
    "from scipy import stats\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIG (UPDATE THESE)\n",
    "# -----------------------------\n",
    "TEST_DIR = r\"C:/Users/vb11574/Desktop/Salmonella_Project/Models/3_SameLearning/Ame_to_Ame/American_Dataset/test\"\n",
    "PTH_DIR  = r\"C:/Users/vb11574/Desktop/Salmonella_Project/Models/3_SameLearning/Ame_to_Ame/Models\"  # folder containing .pth\n",
    "OUTPUT_EXCEL = r\"C:/Users/vb11574/Desktop/Salmonella_Project/Models/3_SameLearning/Ame_to_Ame/2_Ame_to_Ame_Metrics_report.xlsx\"\n",
    "\n",
    "BATCH_SIZE = 64  # increase for faster eval if VRAM allows\n",
    "NUM_WORKERS = min(8, os.cpu_count() or 0)\n",
    "PIN_MEMORY = True\n",
    "PERSISTENT_WORKERS = True if NUM_WORKERS > 0 else False\n",
    "MIXED_PRECISION = True\n",
    "\n",
    "# TF code uses only rescale=1/255 => PyTorch equivalent is ToTensor() only (no ImageNet normalize)\n",
    "USE_IMAGENET_NORMALIZATION = False\n",
    "\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "# If you want the TF-like label names but your folder names differ, edit these:\n",
    "DEFAULT_TARGET_NAMES = [\"healthy\", \"salmo\"]  # only used if len(classes)==2\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers: plots & CI\n",
    "# -----------------------------\n",
    "def save_plot_to_image(fig):\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format=\"png\", dpi=160, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    buf.seek(0)\n",
    "    return XLImage(PILImage.open(buf))\n",
    "\n",
    "def compute_confidence_interval(data, confidence=0.95):\n",
    "    mean_ = float(np.mean(data))\n",
    "    sem_ = stats.sem(data)\n",
    "    margin = float(sem_ * stats.t.ppf((1 + confidence) / 2.0, len(data) - 1))\n",
    "    return mean_, margin\n",
    "\n",
    "# -----------------------------\n",
    "# DataLoader builder (input-size aware)\n",
    "# -----------------------------\n",
    "def make_test_loader(test_dir: str, img_size: int):\n",
    "    tfms = [\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),  # -> [0,1] like TF rescale=1/255\n",
    "    ]\n",
    "    if USE_IMAGENET_NORMALIZATION:\n",
    "        tfms.append(transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD))\n",
    "\n",
    "    ds = datasets.ImageFolder(test_dir, transform=transforms.Compose(tfms))\n",
    "    loader = DataLoader(\n",
    "        ds,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=PIN_MEMORY,\n",
    "        persistent_workers=PERSISTENT_WORKERS,\n",
    "        prefetch_factor=2 if PERSISTENT_WORKERS else None,\n",
    "    )\n",
    "    return ds, loader\n",
    "\n",
    "# -----------------------------\n",
    "# Model builders (must match how your .pth was trained)\n",
    "# Outputs logits [B,1]\n",
    "# -----------------------------\n",
    "def binary_head(in_features: int):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_features, 512),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.Linear(512, 1),\n",
    "    )\n",
    "\n",
    "def build_model(model_name: str):\n",
    "    name = model_name.lower()\n",
    "\n",
    "    if name == \"vgg16\":\n",
    "        m = models.vgg16(weights=None)\n",
    "        m.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        in_feat = m.classifier[0].in_features\n",
    "        m.classifier = binary_head(in_feat)\n",
    "        return m\n",
    "\n",
    "    if name == \"vgg19\":\n",
    "        m = models.vgg19(weights=None)\n",
    "        m.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        in_feat = m.classifier[0].in_features\n",
    "        m.classifier = binary_head(in_feat)\n",
    "        return m\n",
    "\n",
    "    if name == \"mobilenetv2\":\n",
    "        m = models.mobilenet_v2(weights=None)\n",
    "        in_feat = m.classifier[1].in_features\n",
    "        m.classifier = nn.Sequential(nn.Dropout(p=0.2), nn.Linear(in_feat, 1))\n",
    "        return m\n",
    "\n",
    "    if name in [\"mobilenetv3\", \"mobilenetv3large\", \"mobilenetv3_large\"]:\n",
    "        m = models.mobilenet_v3_large(weights=None)\n",
    "        m.classifier = nn.Sequential(\n",
    "            nn.Linear(m.classifier[0].in_features, 512),\n",
    "            nn.Hardswish(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 1),\n",
    "        )\n",
    "        return m\n",
    "\n",
    "    if name == \"densenet121\":\n",
    "        m = models.densenet121(weights=None)\n",
    "        in_feat = m.classifier.in_features\n",
    "        m.classifier = binary_head(in_feat)\n",
    "        return m\n",
    "\n",
    "    if name == \"densenet169\":\n",
    "        m = models.densenet169(weights=None)\n",
    "        in_feat = m.classifier.in_features\n",
    "        m.classifier = binary_head(in_feat)\n",
    "        return m\n",
    "\n",
    "    if name == \"densenet201\":\n",
    "        m = models.densenet201(weights=None)\n",
    "        in_feat = m.classifier.in_features\n",
    "        m.classifier = binary_head(in_feat)\n",
    "        return m\n",
    "\n",
    "    if name == \"resnet50\":\n",
    "        m = models.resnet50(weights=None)\n",
    "        in_feat = m.fc.in_features\n",
    "        m.fc = binary_head(in_feat)\n",
    "        return m\n",
    "\n",
    "    if name == \"resnet101\":\n",
    "        m = models.resnet101(weights=None)\n",
    "        in_feat = m.fc.in_features\n",
    "        m.fc = binary_head(in_feat)\n",
    "        return m\n",
    "\n",
    "    if name == \"resnet152\":\n",
    "        m = models.resnet152(weights=None)\n",
    "        in_feat = m.fc.in_features\n",
    "        m.fc = binary_head(in_feat)\n",
    "        return m\n",
    "\n",
    "    if name == \"inceptionv3\":\n",
    "        # NOTE: torchvision inception is safest with aux_logits=True\n",
    "        m = models.inception_v3(weights=None, aux_logits=True, transform_input=False)\n",
    "        in_feat = m.fc.in_features\n",
    "        m.fc = binary_head(in_feat)\n",
    "        if m.AuxLogits is not None:\n",
    "            aux_in = m.AuxLogits.fc.in_features\n",
    "            m.AuxLogits.fc = nn.Linear(aux_in, 1)\n",
    "        return m\n",
    "\n",
    "    if name == \"efficientnetb0\":\n",
    "        m = models.efficientnet_b0(weights=None)\n",
    "        in_feat = m.classifier[1].in_features\n",
    "        m.classifier = nn.Sequential(nn.Dropout(p=0.5), nn.Linear(in_feat, 1))\n",
    "        return m\n",
    "\n",
    "    if name == \"efficientnetb3\":\n",
    "        m = models.efficientnet_b3(weights=None)\n",
    "        in_feat = m.classifier[1].in_features\n",
    "        m.classifier = nn.Sequential(nn.Dropout(p=0.5), nn.Linear(in_feat, 1))\n",
    "        return m\n",
    "\n",
    "    if name == \"efficientnetb7\":\n",
    "        m = models.efficientnet_b7(weights=None)\n",
    "        in_feat = m.classifier[1].in_features\n",
    "        m.classifier = nn.Sequential(nn.Dropout(p=0.5), nn.Linear(in_feat, 1))\n",
    "        return m\n",
    "\n",
    "    if name == \"xception\":\n",
    "        # Xception isn't in torchvision. If you used it, easiest is timm.\n",
    "        # pip install timm\n",
    "        import timm\n",
    "        m = timm.create_model(\"xception\", pretrained=False, num_classes=1)\n",
    "        return m\n",
    "\n",
    "    raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "\n",
    "def forward_logits(model, x, model_name: str):\n",
    "    out = model(x)\n",
    "    # Inception returns (logits, aux) during train; in eval usually returns logits,\n",
    "    # but be safe:\n",
    "    if model_name.lower() == \"inceptionv3\":\n",
    "        if isinstance(out, tuple):\n",
    "            out = out[0]\n",
    "    return out\n",
    "\n",
    "# -----------------------------\n",
    "# Robust checkpoint loader\n",
    "# -----------------------------\n",
    "def load_pth_weights(model: nn.Module, pth_path: str):\n",
    "    ckpt = torch.load(pth_path, map_location=\"cpu\")\n",
    "\n",
    "    # handle common formats\n",
    "    if isinstance(ckpt, dict):\n",
    "        if \"state_dict\" in ckpt:\n",
    "            state = ckpt[\"state_dict\"]\n",
    "        elif \"model_state_dict\" in ckpt:\n",
    "            state = ckpt[\"model_state_dict\"]\n",
    "        else:\n",
    "            # might already be a state_dict-like dict\n",
    "            state = ckpt\n",
    "    else:\n",
    "        raise ValueError(\"Checkpoint is not a dict; if you did torch.save(model), tell me and I‚Äôll adjust loader.\")\n",
    "\n",
    "    # strip DataParallel prefix\n",
    "    if any(k.startswith(\"module.\") for k in state.keys()):\n",
    "        state = {k.replace(\"module.\", \"\", 1): v for k, v in state.items()}\n",
    "\n",
    "    missing, unexpected = model.load_state_dict(state, strict=False)\n",
    "    return missing, unexpected\n",
    "\n",
    "# -----------------------------\n",
    "# Inference\n",
    "# -----------------------------\n",
    "@torch.no_grad()\n",
    "def predict_proba(model, loader, device, model_name: str):\n",
    "    model.eval()\n",
    "    probs_all = []\n",
    "\n",
    "    for x, _ in loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        with torch.amp.autocast(\"cuda\", enabled=(MIXED_PRECISION and device.type == \"cuda\")):\n",
    "            logits = forward_logits(model, x, model_name)\n",
    "        probs = torch.sigmoid(logits).view(-1).detach().cpu().numpy()\n",
    "        probs_all.append(probs)\n",
    "\n",
    "    return np.concatenate(probs_all, axis=0)\n",
    "\n",
    "# -----------------------------\n",
    "# MAIN: evaluate all .pth in folder\n",
    "# -----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device.type == \"cuda\":\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "wb = Workbook()\n",
    "del wb[\"Sheet\"]\n",
    "\n",
    "pth_files = sorted([f for f in os.listdir(PTH_DIR) if f.lower().endswith(\".pth\")])\n",
    "if not pth_files:\n",
    "    raise RuntimeError(f\"No .pth files found in: {PTH_DIR}\")\n",
    "\n",
    "for fname in pth_files:\n",
    "    pth_path = os.path.join(PTH_DIR, fname)\n",
    "\n",
    "    # IMPORTANT: This assumes your file name starts with the architecture, like:\n",
    "    # \"VGG16_best.pth\", \"DenseNet201_run1.pth\", \"InceptionV3_best.pth\"\n",
    "    model_name = os.path.splitext(fname)[0].split(\"_\")[0]\n",
    "\n",
    "    print(f\"\\nüîç Evaluating {fname}  (model={model_name})\")\n",
    "\n",
    "    try:\n",
    "        # input-size: InceptionV3 / Xception typically need 299\n",
    "        img_size = 299 if model_name.lower() in [\"inceptionv3\", \"xception\"] else 224\n",
    "\n",
    "        test_ds, test_loader = make_test_loader(TEST_DIR, img_size)\n",
    "        class_names = test_ds.classes\n",
    "        target_names = DEFAULT_TARGET_NAMES if len(class_names) == 2 else class_names\n",
    "\n",
    "        model = build_model(model_name).to(device)\n",
    "        missing, unexpected = load_pth_weights(model, pth_path)\n",
    "\n",
    "        if missing:\n",
    "            print(f\"‚ö†Ô∏è Missing keys (first 10): {missing[:10]}\")\n",
    "        if unexpected:\n",
    "            print(f\"‚ö†Ô∏è Unexpected keys (first 10): {unexpected[:10]}\")\n",
    "\n",
    "        y_true = np.array([label for _, label in test_ds.samples], dtype=int)\n",
    "        y_prob = predict_proba(model, test_loader, device, model_name)\n",
    "        y_pred = (y_prob > 0.5).astype(int)\n",
    "\n",
    "        conf = confusion_matrix(y_true, y_pred)\n",
    "        report = classification_report(y_true, y_pred, target_names=target_names, output_dict=True)\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "        precision, recall, _ = precision_recall_curve(y_true, y_prob)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        mAP = average_precision_score(y_true, y_prob)\n",
    "        ci_mean, ci_margin = compute_confidence_interval(y_prob)\n",
    "\n",
    "        # Excel sheet\n",
    "        sheet_name = model_name[:31]\n",
    "        ws = wb.create_sheet(sheet_name)\n",
    "\n",
    "        ws.append([\"Checkpoint\"])\n",
    "        ws.append([\"File\", fname])\n",
    "        ws.append([])\n",
    "\n",
    "        ws.append([\"Summary Metrics\"])\n",
    "        metrics = {\n",
    "            \"Test Accuracy\": report[\"accuracy\"],\n",
    "            \"ROC AUC\": roc_auc,\n",
    "            \"PR AUC\": pr_auc,\n",
    "            \"mAP\": mAP,\n",
    "            \"CI Mean\": ci_mean,\n",
    "            \"CI Margin\": ci_margin,\n",
    "        }\n",
    "\n",
    "        # Add F1s if possible\n",
    "        if len(target_names) == 2 and target_names[0] in report and target_names[1] in report:\n",
    "            metrics[f\"F1_{target_names[0]}\"] = report[target_names[0]][\"f1-score\"]\n",
    "            metrics[f\"F1_{target_names[1]}\"] = report[target_names[1]][\"f1-score\"]\n",
    "\n",
    "        for k, v in metrics.items():\n",
    "            ws.append([k, round(float(v), 6)])\n",
    "        ws.append([])\n",
    "\n",
    "        ws.append([\"Confusion Matrix\"])\n",
    "        conf_df = pd.DataFrame(\n",
    "            conf,\n",
    "            index=[f\"Actual_{target_names[0]}\", f\"Actual_{target_names[1]}\"],\n",
    "            columns=[f\"Pred_{target_names[0]}\", f\"Pred_{target_names[1]}\"],\n",
    "        )\n",
    "        for r in dataframe_to_rows(conf_df, index=True, header=True):\n",
    "            ws.append(r)\n",
    "\n",
    "        # Plots\n",
    "        fig = plt.figure()\n",
    "        plt.plot(fpr, tpr)\n",
    "        plt.title(\"ROC Curve\")\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        ws.add_image(save_plot_to_image(fig), \"J2\")\n",
    "\n",
    "        fig = plt.figure()\n",
    "        plt.plot(recall, precision)\n",
    "        plt.title(\"PR Curve\")\n",
    "        plt.xlabel(\"Recall\")\n",
    "        plt.ylabel(\"Precision\")\n",
    "        ws.add_image(save_plot_to_image(fig), \"J18\")\n",
    "\n",
    "        fig = plt.figure()\n",
    "        sns.heatmap(conf, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        ws.add_image(save_plot_to_image(fig), \"A18\")\n",
    "\n",
    "        print(f\"‚úÖ Done: {model_name} | Acc={report['accuracy']:.4f} | ROC_AUC={roc_auc:.4f} | PR_AUC={pr_auc:.4f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed for {fname}: {e}\")\n",
    "\n",
    "wb.save(OUTPUT_EXCEL)\n",
    "print(f\"\\n‚úÖ Excel report saved to: {OUTPUT_EXCEL}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salmo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
